{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Text Mining: Sentiment Analysis\nComparing Transformer Sentiment Analysis to traditional Sentiment Analysis. \nUsing Text mining\n\n### Dataset: \nSST2 Movie Reviews","metadata":{}},{"cell_type":"code","source":"# installs Run once\n!pip install -q datasets evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T20:18:56.604352Z","iopub.execute_input":"2026-01-02T20:18:56.604583Z","iopub.status.idle":"2026-01-02T20:19:01.441313Z","shell.execute_reply.started":"2026-01-02T20:18:56.604540Z","shell.execute_reply":"2026-01-02T20:19:01.440132Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -q spacy scikit-learn\n!python -m spacy download en_core_web_md","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T20:19:01.443972Z","iopub.execute_input":"2026-01-02T20:19:01.444289Z","iopub.status.idle":"2026-01-02T20:19:23.046865Z","shell.execute_reply.started":"2026-01-02T20:19:01.444256Z","shell.execute_reply":"2026-01-02T20:19:23.045848Z"}},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.12/dist-packages/sqlalchemy/orm/query.py:195: SyntaxWarning: \"is not\" with 'tuple' literal. Did you mean \"!=\"?\n  if entities is not ():\nCollecting en-core-web-md==3.8.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: en-core-web-md\nSuccessfully installed en-core-web-md-3.8.0\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_md')\n\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Setting up dataset with same format as previous work\n\nimport numpy as np\nimport evaluate\nfrom datasets import load_dataset\n\n\ndataset = load_dataset(\"stanfordnlp/sst2\")\n\nprint(\"Original dataset structure:\")\nprint(dataset)\n\n# Create test set\ntrain_valid_test = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\ntrain_valid = train_valid_test[\"train\"].train_test_split(test_size=0.1, seed=42)\n\ndataset[\"train\"] = train_valid[\"train\"]\ndataset[\"validation\"] = train_valid[\"test\"]  # Use as validation\ndataset[\"test\"] = train_valid_test[\"test\"]   # Use as test\n\nprint(\"\\nDataset structure:\")\nprint(f\"  Train: {len(dataset['train'])} samples\")\nprint(f\"  Validation: {len(dataset['validation'])} samples\")\nprint(f\"  Test: {len(dataset['test'])} samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T20:19:23.047991Z","iopub.execute_input":"2026-01-02T20:19:23.048246Z","iopub.status.idle":"2026-01-02T20:19:58.706288Z","shell.execute_reply.started":"2026-01-02T20:19:23.048223Z","shell.execute_reply":"2026-01-02T20:19:58.705007Z"}},"outputs":[{"name":"stderr","text":"2026-01-02 20:19:34.567943: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767385174.781990      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767385174.847875      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767385175.395438      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767385175.395479      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767385175.395481      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767385175.395483      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48c01bcb6d3b4394841b18049964c842"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00001.parquet:   0%|          | 0.00/3.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85a744a91974446ebdd9ed8a19863e94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/validation-00000-of-00001.parquet:   0%|          | 0.00/72.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fec14e1f6f254d498bc912486b7c936c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/test-00000-of-00001.parquet:   0%|          | 0.00/148k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53bbbae1a91d4d66869b8a999d22710d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf7458358852404fae6fa0ebc0385d44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5b5b54388cb4bbdb6c2a85c7ada2271"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1dcebd1f55842bd9493b93ea39dec2f"}},"metadata":{}},{"name":"stdout","text":"Original dataset structure:\nDatasetDict({\n    train: Dataset({\n        features: ['idx', 'sentence', 'label'],\n        num_rows: 67349\n    })\n    validation: Dataset({\n        features: ['idx', 'sentence', 'label'],\n        num_rows: 872\n    })\n    test: Dataset({\n        features: ['idx', 'sentence', 'label'],\n        num_rows: 1821\n    })\n})\n\nDataset structure:\n  Train: 54552 samples\n  Validation: 6062 samples\n  Test: 6735 samples\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"Printing dataset structure for preprocessing","metadata":{}},{"cell_type":"code","source":"print(dataset['train'][0])\nprint(dataset['train'][1])\nprint(dataset['train'][2])\nprint(dataset['train'][3])\nprint(dataset['train'][4])\nprint(dataset['train'][5])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T20:19:58.707572Z","iopub.execute_input":"2026-01-02T20:19:58.708223Z","iopub.status.idle":"2026-01-02T20:19:58.715342Z","shell.execute_reply.started":"2026-01-02T20:19:58.708195Z","shell.execute_reply":"2026-01-02T20:19:58.714114Z"}},"outputs":[{"name":"stdout","text":"{'idx': 26396, 'sentence': 'negligible british comedy . ', 'label': 0}\n{'idx': 5753, 'sentence': 'has no snap ', 'label': 0}\n{'idx': 21514, 'sentence': 'the lines work ', 'label': 1}\n{'idx': 21179, 'sentence': 'is a lumbering load of hokum but ', 'label': 0}\n{'idx': 44976, 'sentence': 'right film ', 'label': 1}\n{'idx': 34302, 'sentence': 'something rare and riveting : ', 'label': 1}\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"Using SpaCy and sci-kit learn for traditional ML model approach","metadata":{}},{"cell_type":"code","source":"# Imports\nimport spacy\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# set up my data\ntrain_data = dataset['train']\nval_data = dataset['validation']\ntest_data = dataset['test']\n\n# extract labels and sentences\ntrain_sentences = train_data['sentence']\ntrain_labels = train_data['label']\n\nval_sentences = val_data['sentence']\nval_labels = val_data['label']\n\ntest_sentences = test_data['sentence']\ntest_labels = test_data['label']\n\nprint(f\"Training samples: {len(train_sentences)}\")\nprint(f\"Validation samples: {len(val_sentences)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T20:19:58.716244Z","iopub.execute_input":"2026-01-02T20:19:58.716514Z","iopub.status.idle":"2026-01-02T20:20:00.307870Z","shell.execute_reply.started":"2026-01-02T20:19:58.716486Z","shell.execute_reply":"2026-01-02T20:20:00.306812Z"}},"outputs":[{"name":"stdout","text":"Training samples: 54552\nValidation samples: 6062\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Feature Extraction\n\nnlp = spacy.load(\"en_core_web_md\")\n\n# Chose TF-IDF method to extract notable features for training models\ndef spacy_tokenizer(sentence):\n    doc = nlp(sentence)\n    \n    tokens = [token.lemma_.lower() for token in doc \n              if not token.is_stop and not token.is_punct and not token.is_space]\n    return tokens\n\n# TF-IDF\ntfidf_vectorizer = TfidfVectorizer(\n    tokenizer=spacy_tokenizer,\n    max_features=10000,\n    ngram_range=(1, 2)\n)\n\nprint(\"Extracting TF-IDF features...\")\nX_train_tfidf = tfidf_vectorizer.fit_transform(train_sentences)\nX_val_tfidf = tfidf_vectorizer.transform(val_sentences)\nX_test_tfidf = tfidf_vectorizer.transform(test_sentences)\n\nprint(f\"TF-IDF shape: {X_train_tfidf.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T20:20:00.308757Z","iopub.execute_input":"2026-01-02T20:20:00.309378Z","iopub.status.idle":"2026-01-02T20:25:48.812357Z","shell.execute_reply.started":"2026-01-02T20:20:00.309355Z","shell.execute_reply":"2026-01-02T20:25:48.811531Z"}},"outputs":[{"name":"stdout","text":"Extracting TF-IDF features...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"TF-IDF shape: (54552, 10000)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"### Train Models\n2 Models selected: \n1. SVM\n2. Logistic Regression","metadata":{}},{"cell_type":"code","source":"def logistic_regression(X_train, X_val, y_train, y_val, feature_name):\n    results = {}\n    print(f\"Training Logistic Regression with {feature_name}...\")\n    model = LogisticRegression(max_iter = 1000, random_state = 42)\n    model.fit(X_train, y_train)\n    predictions = model.predict(X_val)\n    accuracy = accuracy_score(y_val, predictions)\n    \n    print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n    print(\"\\nClassification Report:\")\n    print(classification_report(y_val, predictions, target_names=['Negative', 'Positive']))\n    \n    results['logistic_regression'] = {\n        'model': model,\n        'accuracy': accuracy,\n        'predictions': predictions\n    }\n    return results\n\ndef svm(X_train, X_val, y_train, y_val, feature_name):\n    results = {}\n    print(f\"Training SVM with {feature_name}...\")\n    \n    model = SVC(kernel = 'rbf', C = 1.0, random_state = 42)\n    model.fit(X_train, y_train)\n    \n    predictions = model.predict(X_val)\n    accuracy = accuracy_score(y_val, predictions)\n    \n    print(f\"SVM Accuracy: {accuracy:.4f}\")\n    print(\"\\nClassification Report:\")\n    print(classification_report(y_val, predictions, target_names=['Negative', 'Positive']))\n    \n    results['svm'] = {\n        'model': model,\n        'accuracy': accuracy,\n        'predictions': predictions\n    }\n    \n    return results\n\n\n\n# Convert labels to numpy array\ny_train = np.array(train_labels)\ny_val = np.array(val_labels)\n\n# Train with TF-IDF features\nlr_tfidf = logistic_regression(X_train_tfidf, X_val_tfidf, y_train, y_val, \"TF-IDF Features\")\nsvm_tfidf = svm(X_train_tfidf, X_val_tfidf, y_train, y_val, \"TF-IDF Features\")\n\n\n# Results\nprint(f\"\\nTF-IDF Features:\")\nprint(f\"  Logistic Regression: {lr_tfidf['logistic_regression']['accuracy']:.4f}\")\nprint(f\"  SVM:                 {svm_tfidf['svm']['accuracy']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T00:13:09.654523Z","iopub.execute_input":"2026-01-02T00:13:09.654896Z","iopub.status.idle":"2026-01-02T00:21:29.330645Z","shell.execute_reply.started":"2026-01-02T00:13:09.654862Z","shell.execute_reply":"2026-01-02T00:21:29.329599Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Looking at Test data for final eval\n\ndef svm(X_train, X_val, y_train, y_val, feature_name):\n    results = {}\n    print(f\"Training SVM with {feature_name}...\")\n    \n    model = SVC(kernel = 'rbf', C = 1.0, random_state = 42)\n    model.fit(X_train, y_train)\n    \n    predictions = model.predict(X_val)\n    accuracy = accuracy_score(y_val, predictions)\n    \n    print(f\"SVM Accuracy: {accuracy:.4f}\")\n    print(\"\\nClassification Report:\")\n    print(classification_report(y_val, predictions, target_names=['Negative', 'Positive']))\n    \n    results['svm'] = {\n        'model': model,\n        'accuracy': accuracy,\n        'predictions': predictions\n    }\n    \n    return results\n\n\ny_train = np.array(train_labels)\ny_test = np.array(test_labels)\n\nsvm_tfidf = svm(X_train_tfidf, X_test_tfidf, y_train, y_test, \"TF-IDF Features\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T20:25:48.813848Z","iopub.execute_input":"2026-01-02T20:25:48.814116Z","iopub.status.idle":"2026-01-02T20:30:48.619532Z","shell.execute_reply.started":"2026-01-02T20:25:48.814094Z","shell.execute_reply":"2026-01-02T20:30:48.618587Z"}},"outputs":[{"name":"stdout","text":"Training SVM with TF-IDF Features...\nSVM Accuracy: 0.8889\n\nClassification Report:\n              precision    recall  f1-score   support\n\n    Negative       0.87      0.88      0.88      3044\n    Positive       0.90      0.89      0.90      3691\n\n    accuracy                           0.89      6735\n   macro avg       0.89      0.89      0.89      6735\nweighted avg       0.89      0.89      0.89      6735\n\n","output_type":"stream"}],"execution_count":7}]}